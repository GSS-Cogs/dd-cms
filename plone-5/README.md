# Plone

Before running Plone, you may need to install some [Prerequisites](./plone.md#1-pre-requisites). 
The following guidance assumes working versions of docker and access to GCP for fetching SQL backups.
You may also need to run some manual steps to [configure plone](./plone.md#configure-plone) once your containers are running.

Plone requires the following env vars to run and connect to the postgres backend.

| Env var | Description | Deployed Value |
| --- | ---- | --- |
| POSTGRES_DB | The database name used in postgres | Same as environment, i.e sandbox/staging/production |
| POSTGRES_USER | The user plone connect to postgres with | `plone`|
| POSTGRES_PASSWORD | The password plone connect to postgres with | A large random string generated by terraform IAC |
| POSTGRES_HOST | The IP address of the database | An internal GCP IP address in the appropriate VPC. |

Within a deployment to environment buld pipleine everything bar `POSTGRES_USER` needs to be set using a docker `--buld-arg`.

## Running plone locally with PostgresDB

When run in an environment Plone uses a postgres database hosted on cloudsql.

To create this locally, you need to...

### 1. Run postgres locally

Run postgres with docker (pick a suitable `<password>` for your own local development work).

```
docker run -e POSTGRES_USER=plone -e POSTGRES_DB=local -e POSTGRES_PASSWORD=<password> --name plone-postgres -d -p 5432:5432 postgres:14
```

notes:
- the `--name` here is just the name of the docker container we're creating, it has nothing to do with the DB connection.
- its `postgres:14` as that's what CloudSQL is using at time of writing, you can check this via the CloudSQL page in the GCP console.


### 2. Import a representative data backup from GCP

Download the desired backup from the google bucket `cms-sql-backup`. Sandbox or staging backups are preferred for local running. Using production backups should only occur with Service Manager consent, as there are security risks involved.

Import the SQL into your locally running postgres instance via:

```
docker exec -i plone-postgres psql -U plone -d local < <PATH_TO_DOWNLOADED_SQL_DUMP>.sql
```

_Note - you will get warnings for missing "cloudql-*" roles but it still works._

### 3. Run plone locally with docker

Build the image (from within the /plone-5 directory).

```
# Note the "." means "current context, i.e ./*", so instructs docker to use
# the Dockerfile in the current working directory - plone-5.
docker build --build-arg POSTGRES_PASSWORD=<password> --tag plone .  
```

run it

```
docker run -p 8080:8080 plone
```

**Important** - there's no oauth handler set up for localhost, you'll need to log into your zope user (for whatever env you copied the database from) to bypass this broken handshake.

Any issues, you can sanity check what's been set in the `zope.conf` (by the dockerfile) via:

```
docker run -it -p 8080:8080 plone /bin/sh

# then
cat /plone/instance/parts/instance/etc/zope.conf

# then exit to leave container.
```


## Additional Info

To connect to a local plone instance (docker or otherwise) with volto, from `../volto` run:

```
RAZZLE_DEV_PROXY_API_PATH=http://localhost:8080/<site> yarn start:dev
```

for example

```
RAZZLE_DEV_PROXY_API_PATH=http://localhost:8080/climate-change yarn start:dev
```
